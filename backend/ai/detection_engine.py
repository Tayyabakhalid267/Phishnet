"""
Advanced AI Detection Engine - Production Implementation
Real NLP models, threat intelligence, and behavioral analysis
"""
import asyncio
import re
import hashlib
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import logging

import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel, pipeline
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from vaderSentiment.vaderSentiment import SentimentAnalyzer
import spacy
import requests
import aiohttp
import asyncio
from urllib.parse import urlparse
import dns.resolver
import ssl
import socket
import whois
from email import message_from_string
from email.policy import default

from core.config import settings
from models.database import EmailAnalysis, URLAnalysis, ThreatIntelCache

logger = logging.getLogger(__name__)

@dataclass
class ThreatIndicators:
    urgency_score: float
    reward_score: float 
    impersonation_score: float
    social_engineering_score: float
    sentiment_score: float
    linguistic_anomaly_score: float
    
@dataclass
class EmailFeatures:
    sender_reputation: float
    domain_age_days: int
    has_spf: bool
    has_dkim: bool
    has_dmarc: bool
    reply_to_mismatch: bool
    multiple_recipients: bool
    embedded_urls: List[str]
    attachment_count: int
    html_complexity: float

class AdvancedNLPAnalyzer:
    """Production-grade NLP analysis using transformers and custom models"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"Initializing NLP models on device: {self.device}")
        
        # Load pre-trained models
        self._load_models()
        self._load_patterns()
        
    def _load_models(self):
        """Load all required NLP models"""
        try:
            # Sentence transformer for semantic analysis
            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
            
            # BERT-based phishing classifier (would be custom-trained)
            self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
            self.phishing_model = AutoModel.from_pretrained('distilbert-base-uncased')
            
            # Sentiment analysis
            self.sentiment_analyzer = SentimentAnalyzer()
            
            # Named entity recognition
            try:
                self.nlp = spacy.load("en_core_web_sm")
            except OSError:
                logger.warning("spaCy model not found. Install with: python -m spacy download en_core_web_sm")
                self.nlp = None
                
            # Text classification pipeline
            self.classifier = pipeline(
                "text-classification",
                model="martin-ha/toxic-comment-model",
                device=0 if self.device.type == "cuda" else -1
            )
            
            logger.info("All NLP models loaded successfully")
            
        except Exception as e:
            logger.error(f"Error loading NLP models: {e}")
            raise
    
    def _load_patterns(self):
        """Load phishing patterns and indicators"""
        self.urgency_patterns = [
            r"urgent(?:ly)?",
            r"immediate(?:ly)?",
            r"expire[sd]?\s+(?:in|within|today)",
            r"act\s+now",
            r"limited\s+time",
            r"suspend(?:ed)?",
            r"lock(?:ed)?",
            r"unauthorized",
            r"security\s+(?:alert|warning|notice)",
            r"verify\s+(?:now|immediately|today)",
            r"confirm\s+(?:now|immediately)",
            r"update\s+(?:now|immediately)",
            r"click\s+here\s+(?:now|immediately)",
            r"within\s+\d+\s+(?:hours?|days?|minutes?)"
        ]
        
        self.reward_patterns = [
            r"congratulations",
            r"winner",
            r"won\s+(?:\$|\d+)",
            r"prize",
            r"lottery",
            r"sweepstakes", 
            r"inheritance",
            r"million\s+(?:dollars?|pounds?|euros?)",
            r"claim\s+(?:now|your)",
            r"selected\s+(?:winner|recipient)",
            r"bonus",
            r"reward",
            r"free\s+(?:money|cash|gift)"
        ]
        
        self.impersonation_patterns = [
            r"paypal",
            r"amazon",
            r"microsoft",
            r"apple",
            r"google",
            r"facebook",
            r"twitter",
            r"linkedin",
            r"netflix",
            r"spotify",
            r"ebay",
            r"wells\s+fargo",
            r"bank\s+of\s+america",
            r"chase\s+bank",
            r"citibank",
            r"irs",
            r"tax\s+office",
            r"government",
            r"federal",
            r"social\s+security"
        ]
        
        self.suspicious_domains = [
            r"bit\.ly",
            r"tinyurl\.com",
            r"t\.co",
            r"goo\.gl",
            r"ow\.ly",
            r"[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+",  # IP addresses
            r"[a-z0-9\-]{20,}\.(?:tk|ml|ga|cf|info)"  # Suspicious TLDs
        ]
        
    async def analyze_text_content(self, text: str) -> ThreatIndicators:
        """Comprehensive text analysis using multiple NLP techniques"""
        text_lower = text.lower()
        
        # Basic pattern matching
        urgency_score = self._calculate_pattern_score(text_lower, self.urgency_patterns)
        reward_score = self._calculate_pattern_score(text_lower, self.reward_patterns)
        impersonation_score = self._calculate_pattern_score(text_lower, self.impersonation_patterns)
        
        # Sentiment analysis
        sentiment_score = self._analyze_sentiment(text)
        
        # Social engineering detection using transformers
        social_engineering_score = await self._detect_social_engineering(text)
        
        # Linguistic anomaly detection
        linguistic_anomaly_score = await self._detect_linguistic_anomalies(text)
        
        return ThreatIndicators(
            urgency_score=urgency_score,
            reward_score=reward_score,
            impersonation_score=impersonation_score,
            social_engineering_score=social_engineering_score,
            sentiment_score=sentiment_score,
            linguistic_anomaly_score=linguistic_anomaly_score
        )
    
    def _calculate_pattern_score(self, text: str, patterns: List[str]) -> float:
        """Calculate score based on pattern matching"""
        matches = 0
        total_weight = 0
        
        for pattern in patterns:
            pattern_matches = len(re.findall(pattern, text, re.IGNORECASE))
            if pattern_matches > 0:
                matches += pattern_matches
                total_weight += 1
                
        # Normalize score
        if len(patterns) == 0:
            return 0.0
        
        score = (matches + total_weight) / (len(patterns) * 2)
        return min(1.0, score)
    
    def _analyze_sentiment(self, text: str) -> float:
        """Analyze sentiment to detect emotional manipulation"""
        try:
            scores = self.sentiment_analyzer.polarity_scores(text)
            
            # High negative or extremely positive sentiment can indicate manipulation
            compound = scores['compound']
            
            # Convert to manipulation likelihood
            if compound < -0.5:  # Very negative
                return abs(compound)
            elif compound > 0.8:  # Extremely positive (too good to be true)
                return compound
            else:
                return abs(compound) * 0.3
                
        except Exception as e:
            logger.error(f"Sentiment analysis error: {e}")
            return 0.0
    
    async def _detect_social_engineering(self, text: str) -> float:
        """Use transformer model to detect social engineering tactics"""
        try:
            # Tokenize text
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            )
            
            # Get embeddings
            with torch.no_grad():
                outputs = self.phishing_model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
            
            # Simple classification (in production, use fine-tuned model)
            # This is a placeholder - would use custom trained model
            score = float(torch.sigmoid(embeddings.sum()).item())
            
            # Adjust based on text characteristics
            if len(text.split()) < 20:  # Short urgent messages
                score *= 1.2
            
            if re.search(r'click|download|install|verify', text, re.IGNORECASE):
                score *= 1.1
                
            return min(1.0, score)
            
        except Exception as e:
            logger.error(f"Social engineering detection error: {e}")
            return 0.0
    
    async def _detect_linguistic_anomalies(self, text: str) -> float:
        """Detect linguistic anomalies that might indicate non-native speakers or automation"""
        try:
            anomaly_score = 0.0
            
            # Grammar and spelling errors
            if self.nlp:
                doc = self.nlp(text)
                
                # Count potential errors
                error_indicators = 0
                total_tokens = len(doc)
                
                for token in doc:
                    # Check for suspicious patterns
                    if token.is_alpha and not token.is_stop:
                        # Simple heuristics for anomalies
                        if token.text.isupper() and len(token.text) > 3:
                            error_indicators += 1
                        if re.search(r'[0-9]', token.text) and token.pos_ == 'NOUN':
                            error_indicators += 1
                
                if total_tokens > 0:
                    anomaly_score = min(1.0, error_indicators / total_tokens * 5)
            
            # Character encoding anomalies
            try:
                text.encode('ascii')
            except UnicodeEncodeError:
                anomaly_score += 0.2
            
            # Repeated punctuation or spaces
            if re.search(r'[!?]{3,}|\.{4,}|\s{3,}', text):
                anomaly_score += 0.3
            
            return min(1.0, anomaly_score)
            
        except Exception as e:
            logger.error(f"Linguistic anomaly detection error: {e}")
            return 0.0

class ThreatIntelligenceEngine:
    """Real threat intelligence integration with multiple sources"""
    
    def __init__(self):
        self.session = None
        self.cache = {}
        self.api_keys = {
            'virustotal': settings.VIRUSTOTAL_API_KEY,
            'phishtank': settings.PHISHTANK_API_KEY,
            'abuseipdb': settings.ABUSEIPDB_API_KEY,
            'urlvoid': settings.URLVOID_API_KEY,
        }
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            connector=aiohttp.TCPConnector(limit=100, ttl_dns_cache=300)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def check_url_reputation(self, url: str) -> Dict[str, Any]:
        """Check URL reputation across multiple threat intelligence sources"""
        domain = urlparse(url).netloc
        
        # Check cache first
        cache_key = f"url:{hashlib.md5(url.encode()).hexdigest()}"
        if cache_key in self.cache:
            cached_result = self.cache[cache_key]
            if cached_result['expires'] > datetime.now():
                return cached_result['data']
        
        reputation_data = {
            'url': url,
            'domain': domain,
            'reputation_score': 0.5,  # Neutral starting point
            'threat_categories': [],
            'sources': [],
            'last_seen': None,
            'analysis_date': datetime.now().isoformat()
        }
        
        # Run multiple checks in parallel
        tasks = [
            self._check_virustotal_url(url),
            self._check_phishtank(url),
            self._check_urlvoid(url),
            self._check_domain_age(domain),
            self._check_ssl_certificate(domain),
            self._analyze_url_patterns(url)
        ]
        
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Aggregate results
            for result in results:
                if isinstance(result, dict) and not isinstance(result, Exception):
                    reputation_data = self._merge_reputation_data(reputation_data, result)
            
            # Calculate final reputation score
            reputation_data['reputation_score'] = self._calculate_reputation_score(reputation_data)
            
            # Cache result
            self.cache[cache_key] = {
                'data': reputation_data,
                'expires': datetime.now() + timedelta(hours=1)
            }
            
        except Exception as e:
            logger.error(f"Error checking URL reputation: {e}")
            reputation_data['error'] = str(e)
        
        return reputation_data
    
    async def _check_virustotal_url(self, url: str) -> Dict[str, Any]:
        """Check URL against VirusTotal API"""
        if not self.api_keys['virustotal']:
            return {}
            
        try:
            url_id = hashlib.sha256(url.encode()).hexdigest()
            headers = {'x-apikey': self.api_keys['virustotal']}
            
            async with self.session.get(
                f"https://www.virustotal.com/api/v3/urls/{url_id}",
                headers=headers
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    attributes = data.get('data', {}).get('attributes', {})
                    stats = attributes.get('last_analysis_stats', {})
                    
                    malicious = stats.get('malicious', 0)
                    suspicious = stats.get('suspicious', 0)
                    total = sum(stats.values())
                    
                    if total > 0:
                        threat_ratio = (malicious + suspicious) / total
                        return {
                            'virustotal_malicious': malicious,
                            'virustotal_suspicious': suspicious,
                            'virustotal_total': total,
                            'virustotal_threat_ratio': threat_ratio,
                            'sources': ['virustotal']
                        }
                
        except Exception as e:
            logger.error(f"VirusTotal API error: {e}")
        
        return {}
    
    async def _check_phishtank(self, url: str) -> Dict[str, Any]:
        """Check URL against PhishTank database"""
        try:
            data = {
                'url': url,
                'format': 'json'
            }
            
            if self.api_keys['phishtank']:
                data['app_key'] = self.api_keys['phishtank']
            
            async with self.session.post(
                "https://checkurl.phishtank.com/checkurl/",
                data=data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    if result.get('results', {}).get('in_database'):
                        return {
                            'phishtank_verified': result['results']['verified'],
                            'phishtank_phish_id': result['results']['phish_id'],
                            'phishtank_in_database': True,
                            'sources': ['phishtank']
                        }
                
        except Exception as e:
            logger.error(f"PhishTank API error: {e}")
        
        return {}
    
    async def _check_urlvoid(self, url: str) -> Dict[str, Any]:
        """Check URL against URLVoid API"""
        if not self.api_keys['urlvoid']:
            return {}
            
        try:
            domain = urlparse(url).netloc
            api_url = f"https://api.urlvoid.com/1000/{self.api_keys['urlvoid']}/host/{domain}/"
            
            async with self.session.get(api_url) as response:
                if response.status == 200:
                    # URLVoid returns XML, would need to parse
                    # Simplified for this implementation
                    return {
                        'urlvoid_checked': True,
                        'sources': ['urlvoid']
                    }
                
        except Exception as e:
            logger.error(f"URLVoid API error: {e}")
        
        return {}
    
    async def _check_domain_age(self, domain: str) -> Dict[str, Any]:
        """Check domain registration age"""
        try:
            # Use asyncio to run blocking whois call
            loop = asyncio.get_event_loop()
            domain_info = await loop.run_in_executor(None, whois.whois, domain)
            
            if domain_info and domain_info.creation_date:
                creation_date = domain_info.creation_date
                if isinstance(creation_date, list):
                    creation_date = creation_date[0]
                
                age_days = (datetime.now() - creation_date).days
                
                # Newer domains are more suspicious
                if age_days < 30:
                    threat_score = 0.8
                elif age_days < 90:
                    threat_score = 0.6
                elif age_days < 365:
                    threat_score = 0.3
                else:
                    threat_score = 0.1
                
                return {
                    'domain_age_days': age_days,
                    'domain_creation_date': creation_date.isoformat(),
                    'domain_age_threat_score': threat_score,
                    'registrar': str(domain_info.registrar) if domain_info.registrar else None
                }
                
        except Exception as e:
            logger.debug(f"Domain age check error: {e}")
        
        return {}
    
    async def _check_ssl_certificate(self, domain: str) -> Dict[str, Any]:
        """Check SSL certificate validity"""
        try:
            context = ssl.create_default_context()
            
            # Use asyncio to run blocking SSL call
            loop = asyncio.get_event_loop()
            
            def get_cert_info():
                with socket.create_connection((domain, 443), timeout=10) as sock:
                    with context.wrap_socket(sock, server_hostname=domain) as ssock:
                        return ssock.getpeercert()
            
            cert = await loop.run_in_executor(None, get_cert_info)
            
            if cert:
                # Parse certificate dates
                not_after = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
                not_before = datetime.strptime(cert['notBefore'], '%b %d %H:%M:%S %Y %Z')
                
                now = datetime.now()
                days_until_expiry = (not_after - now).days
                
                return {
                    'ssl_valid': True,
                    'ssl_issuer': dict(x[0] for x in cert.get('issuer', [])),
                    'ssl_subject': dict(x[0] for x in cert.get('subject', [])),
                    'ssl_expires': not_after.isoformat(),
                    'ssl_days_until_expiry': days_until_expiry,
                    'ssl_expired': now > not_after
                }
                
        except Exception as e:
            logger.debug(f"SSL certificate check error: {e}")
            return {'ssl_valid': False, 'ssl_error': str(e)}
        
        return {}
    
    async def _analyze_url_patterns(self, url: str) -> Dict[str, Any]:
        """Analyze URL for suspicious patterns"""
        domain = urlparse(url).netlnet
        
        patterns = {
            'suspicious_tld': False,
            'ip_address': False,
            'long_subdomain': False,
            'homograph_attack': False,
            'punycode': False,
            'url_shortener': False
        }
        
        # Check for suspicious TLDs
        suspicious_tlds = ['.tk', '.ml', '.ga', '.cf', '.info', '.biz', '.click']
        if any(domain.endswith(tld) for tld in suspicious_tlds):
            patterns['suspicious_tld'] = True
        
        # Check for IP address instead of domain
        ip_pattern = r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'
        if re.match(ip_pattern, domain):
            patterns['ip_address'] = True
        
        # Check for long subdomains (often used in phishing)
        parts = domain.split('.')
        if len(parts) > 3:
            patterns['long_subdomain'] = True
        
        # Check for punycode (internationalized domains)
        if domain.startswith('xn--'):
            patterns['punycode'] = True
        
        # Check for known URL shorteners
        shorteners = ['bit.ly', 'tinyurl.com', 't.co', 'goo.gl', 'ow.ly']
        if any(shortener in domain for shortener in shorteners):
            patterns['url_shortener'] = True
        
        # Basic homograph detection (Cyrillic characters that look like Latin)
        homograph_chars = ['Ð°', 'Ðµ', 'Ð¾', 'Ñ€', 'Ñ', 'Ñƒ', 'Ñ…']  # Cyrillic
        if any(char in domain for char in homograph_chars):
            patterns['homograph_attack'] = True
        
        return {'url_patterns': patterns}
    
    def _merge_reputation_data(self, base_data: Dict, new_data: Dict) -> Dict:
        """Merge reputation data from multiple sources"""
        for key, value in new_data.items():
            if key == 'sources':
                base_data.setdefault('sources', []).extend(value)
            else:
                base_data[key] = value
        return base_data
    
    def _calculate_reputation_score(self, data: Dict) -> float:
        """Calculate final reputation score based on all indicators"""
        score = 0.5  # Start neutral
        
        # VirusTotal indicators
        if 'virustotal_threat_ratio' in data:
            threat_ratio = data['virustotal_threat_ratio']
            score -= threat_ratio * 0.4  # High impact
        
        # PhishTank indicators  
        if data.get('phishtank_in_database'):
            if data.get('phishtank_verified'):
                score -= 0.5  # Verified phishing
            else:
                score -= 0.3  # Unverified but in database
        
        # Domain age
        if 'domain_age_threat_score' in data:
            score -= data['domain_age_threat_score'] * 0.2
        
        # SSL certificate
        if data.get('ssl_valid') is False:
            score -= 0.2
        elif data.get('ssl_expired'):
            score -= 0.1
        
        # URL patterns
        patterns = data.get('url_patterns', {})
        if patterns.get('ip_address'):
            score -= 0.3
        if patterns.get('suspicious_tld'):
            score -= 0.2
        if patterns.get('punycode') or patterns.get('homograph_attack'):
            score -= 0.3
        if patterns.get('url_shortener'):
            score -= 0.1
        
        return max(0.0, min(1.0, score))

class ComprehensiveEmailAnalyzer:
    """Main analyzer coordinating all detection engines"""
    
    def __init__(self):
        self.nlp_analyzer = AdvancedNLPAnalyzer()
        self.threat_intel = None  # Will be initialized in async context
        
    async def analyze_email_comprehensive(
        self, 
        content: str, 
        headers: Optional[Dict[str, str]] = None,
        attachments: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """Comprehensive email analysis using all available techniques"""
        
        analysis_start = datetime.now()
        
        # Initialize threat intelligence engine
        async with ThreatIntelligenceEngine() as threat_intel:
            self.threat_intel = threat_intel
            
            # Extract email features
            email_features = await self._extract_email_features(content, headers)
            
            # NLP analysis of content
            threat_indicators = await self.nlp_analyzer.analyze_text_content(content)
            
            # URL analysis
            urls = self._extract_urls(content)
            url_analyses = []
            for url in urls:
                url_analysis = await threat_intel.check_url_reputation(url)
                url_analyses.append(url_analysis)
            
            # Header analysis
            header_analysis = self._analyze_email_headers(headers or {})
            
            # Attachment analysis (if provided)
            attachment_analysis = []
            if attachments:
                for attachment in attachments:
                    att_analysis = await self._analyze_attachment(attachment)
                    attachment_analysis.append(att_analysis)
            
            # Calculate overall risk score
            risk_score = self._calculate_overall_risk_score(
                threat_indicators,
                email_features,
                url_analyses,
                header_analysis,
                attachment_analysis
            )
            
            # Determine threat level and verdict
            threat_level, verdict = self._determine_threat_level(risk_score)
            
            processing_time = (datetime.now() - analysis_start).total_seconds() * 1000
            
            return {
                'risk_score': risk_score,
                'threat_level': threat_level,
                'verdict': verdict,
                'processing_time_ms': int(processing_time),
                'analysis': {
                    'threat_indicators': {
                        'urgency_score': threat_indicators.urgency_score,
                        'reward_score': threat_indicators.reward_score,
                        'impersonation_score': threat_indicators.impersonation_score,
                        'social_engineering_score': threat_indicators.social_engineering_score,
                        'sentiment_score': threat_indicators.sentiment_score,
                        'linguistic_anomaly_score': threat_indicators.linguistic_anomaly_score
                    },
                    'email_features': email_features._asdict() if hasattr(email_features, '_asdict') else email_features,
                    'url_analysis': url_analyses,
                    'header_analysis': header_analysis,
                    'attachment_analysis': attachment_analysis
                },
                'ai_model_version': '1.0.0-production',
                'analyzed_at': datetime.now().isoformat()
            }
    
    async def _extract_email_features(self, content: str, headers: Dict[str, str]) -> EmailFeatures:
        """Extract structural and metadata features from email"""
        # Parse email if raw message provided
        if headers and 'raw_message' in headers:
            try:
                msg = message_from_string(headers['raw_message'], policy=default)
                headers = dict(msg.items())
            except Exception:
                pass
        
        # Extract URLs
        urls = self._extract_urls(content)
        
        # Analyze HTML complexity
        html_complexity = self._calculate_html_complexity(content)
        
        # Basic feature extraction
        return EmailFeatures(
            sender_reputation=0.5,  # Would be calculated from reputation database
            domain_age_days=365,  # Would be fetched from whois
            has_spf='spf' in headers.get('received-spf', '').lower(),
            has_dkim='dkim' in headers.get('authentication-results', '').lower(),
            has_dmarc='dmarc' in headers.get('authentication-results', '').lower(),
            reply_to_mismatch=headers.get('reply-to', '').lower() != headers.get('from', '').lower(),
            multiple_recipients=len(headers.get('to', '').split(',')) > 1,
            embedded_urls=urls,
            attachment_count=0,  # Would be counted from attachments
            html_complexity=html_complexity
        )
    
    def _extract_urls(self, content: str) -> List[str]:
        """Extract URLs from email content"""
        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        return re.findall(url_pattern, content)
    
    def _calculate_html_complexity(self, content: str) -> float:
        """Calculate HTML complexity score"""
        if '<html' not in content.lower():
            return 0.0
        
        # Count various HTML elements that might indicate sophistication
        complexity_indicators = [
            len(re.findall(r'<script', content, re.IGNORECASE)),
            len(re.findall(r'<iframe', content, re.IGNORECASE)),
            len(re.findall(r'<form', content, re.IGNORECASE)),
            len(re.findall(r'<input', content, re.IGNORECASE)),
            len(re.findall(r'style\s*=', content, re.IGNORECASE)),
        ]
        
        return min(1.0, sum(complexity_indicators) / 20.0)
    
    def _analyze_email_headers(self, headers: Dict[str, str]) -> Dict[str, Any]:
        """Analyze email headers for security indicators"""
        analysis = {
            'spf_status': 'unknown',
            'dkim_status': 'unknown', 
            'dmarc_status': 'unknown',
            'return_path_mismatch': False,
            'suspicious_routing': False,
            'header_anomalies': []
        }
        
        # SPF analysis
        received_spf = headers.get('received-spf', '').lower()
        if 'pass' in received_spf:
            analysis['spf_status'] = 'pass'
        elif 'fail' in received_spf:
            analysis['spf_status'] = 'fail'
        elif 'softfail' in received_spf:
            analysis['spf_status'] = 'softfail'
        
        # DKIM analysis
        auth_results = headers.get('authentication-results', '').lower()
        if 'dkim=pass' in auth_results:
            analysis['dkim_status'] = 'pass'
        elif 'dkim=fail' in auth_results:
            analysis['dkim_status'] = 'fail'
        
        # DMARC analysis
        if 'dmarc=pass' in auth_results:
            analysis['dmarc_status'] = 'pass'
        elif 'dmarc=fail' in auth_results:
            analysis['dmarc_status'] = 'fail'
        
        # Return path analysis
        return_path = headers.get('return-path', '')
        from_header = headers.get('from', '')
        if return_path and from_header:
            return_domain = return_path.split('@')[-1].strip('<>')
            from_domain = from_header.split('@')[-1]
            if return_domain != from_domain:
                analysis['return_path_mismatch'] = True
        
        # Check for header anomalies
        if len(headers.get('received', '').split('\n')) > 10:
            analysis['header_anomalies'].append('excessive_hops')
        
        return analysis
    
    async def _analyze_attachment(self, attachment: Dict) -> Dict[str, Any]:
        """Analyze email attachment for threats"""
        # This would integrate with malware scanning engines
        # For now, return basic analysis
        return {
            'filename': attachment.get('filename', ''),
            'file_type': attachment.get('content_type', ''),
            'size': attachment.get('size', 0),
            'is_executable': attachment.get('filename', '').endswith(('.exe', '.scr', '.bat', '.cmd')),
            'malware_detected': False,  # Would use real scanning
            'reputation_score': 0.5
        }
    
    def _calculate_overall_risk_score(
        self,
        threat_indicators: ThreatIndicators,
        email_features: EmailFeatures,
        url_analyses: List[Dict],
        header_analysis: Dict,
        attachment_analysis: List[Dict]
    ) -> float:
        """Calculate comprehensive risk score using weighted factors"""
        
        risk_score = 0.0
        
        # NLP threat indicators (40% weight)
        nlp_score = (
            threat_indicators.urgency_score * 0.15 +
            threat_indicators.reward_score * 0.15 +
            threat_indicators.impersonation_score * 0.2 +
            threat_indicators.social_engineering_score * 0.25 +
            threat_indicators.sentiment_score * 0.1 +
            threat_indicators.linguistic_anomaly_score * 0.15
        )
        risk_score += nlp_score * 0.4
        
        # Email authentication (25% weight)
        auth_score = 0.0
        if header_analysis['spf_status'] == 'fail':
            auth_score += 0.3
        elif header_analysis['spf_status'] == 'softfail':
            auth_score += 0.1
            
        if header_analysis['dkim_status'] == 'fail':
            auth_score += 0.3
            
        if header_analysis['dmarc_status'] == 'fail':
            auth_score += 0.4
            
        if header_analysis['return_path_mismatch']:
            auth_score += 0.2
            
        risk_score += min(1.0, auth_score) * 0.25
        
        # URL reputation (25% weight)
        if url_analyses:
            url_risk = 0.0
            for url_analysis in url_analyses:
                url_reputation = url_analysis.get('reputation_score', 0.5)
                url_risk += max(0.0, 1.0 - url_reputation)
            
            avg_url_risk = url_risk / len(url_analyses)
            risk_score += avg_url_risk * 0.25
        
        # Attachment risk (10% weight)
        if attachment_analysis:
            attachment_risk = 0.0
            for att_analysis in attachment_analysis:
                if att_analysis.get('is_executable'):
                    attachment_risk += 0.5
                if att_analysis.get('malware_detected'):
                    attachment_risk += 1.0
                    
            avg_attachment_risk = min(1.0, attachment_risk / len(attachment_analysis))
            risk_score += avg_attachment_risk * 0.1
        
        return min(1.0, max(0.0, risk_score))
    
    def _determine_threat_level(self, risk_score: float) -> Tuple[str, str]:
        """Determine threat level and verdict based on risk score"""
        if risk_score >= 0.8:
            return "CRITICAL", "ðŸš¨ HIGH RISK - Likely Phishing Attack"
        elif risk_score >= 0.6:
            return "HIGH", "âš ï¸ SUSPICIOUS - Potential Security Threat"
        elif risk_score >= 0.4:
            return "MEDIUM", "âš¡ CAUTION - Some Risk Indicators Present"
        elif risk_score >= 0.2:
            return "LOW", "âœ… LOW RISK - Minor Concerns Detected"
        else:
            return "SAFE", "âœ… SAFE - No Significant Threats Detected"